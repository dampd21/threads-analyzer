# src/analyzer.py
# Meta ì»¤ë®¤ë‹ˆí‹° ê·œì • ê¸°ë°˜ ë¶„ì„ê¸°

from difflib import SequenceMatcher
from guidelines import COMMUNITY_GUIDELINES, SEVERITY_SCORES, COMBINATION_BONUS

class GuidelineAnalyzer:
    def __init__(self):
        self.guidelines = COMMUNITY_GUIDELINES
        self.severity_scores = SEVERITY_SCORES
        self.combination_bonus = COMBINATION_BONUS
    
    def analyze_post(self, post: dict) -> dict:
        """
        ë‹¨ì¼ ê²Œì‹œë¬¼ì„ ê³µì‹ ê°€ì´ë“œë¼ì¸ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„
        """
        text = post.get("text", "")
        
        analysis = {
            "username": post.get("username", ""),
            "text": text,
            "datetime": post.get("datetime", ""),
            "link": post.get("link", ""),
            "likes": post.get("likes", 0),
            "replies": post.get("replies", 0),
            "reposts": post.get("reposts", 0),
            
            # ìœ„ë°˜ ë¶„ì„ ê²°ê³¼
            "violations": [],  # ê°ì§€ëœ ìœ„ë°˜ ëª©ë¡
            "violation_details": [],  # ìƒì„¸ ì„¤ëª…
            
            # ì¢…í•© ì ìˆ˜
            "risk_score": 0,
            "risk_level": "âœ… ì•ˆì „",
            "official_policy_refs": [],  # ê´€ë ¨ ê³µì‹ ì •ì±… ì°¸ì¡°
            "recommendations": []
        }
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ìœ„ë°˜ ê²€ì‚¬
        detected_subcategories = []
        
        for category, category_data in self.guidelines.items():
            for subcategory, subcat_data in category_data.get("subcategories", {}).items():
                violation = self._check_violation(text, subcat_data)
                
                if violation["is_violation"]:
                    detected_subcategories.append((category, subcategory))
                    
                    base_score = self.severity_scores.get(category, {}).get(subcategory, 50)
                    
                    analysis["violations"].append({
                        "category": category,
                        "subcategory": subcategory,
                        "matched_indicators": violation["matched_indicators"],
                        "matched_keywords": violation["matched_keywords"],
                        "base_score": base_score
                    })
                    
                    analysis["violation_details"].append(
                        f"[{category}/{subcategory}] {', '.join(violation['matched_indicators'][:2])}"
                    )
                    
                    analysis["official_policy_refs"].append(
                        f"ì»¤ë®¤ë‹ˆí‹° ê·œì • > {category.replace('_', ' ')} > {subcategory.replace('_', ' ')}"
                    )
        
        # ìœ„í—˜ ì ìˆ˜ ê³„ì‚°
        analysis["risk_score"] = self._calculate_risk_score(detected_subcategories, analysis["violations"])
        analysis["risk_level"] = self._get_risk_level(analysis["risk_score"])
        
        # ê¶Œê³ ì‚¬í•­ ìƒì„±
        analysis["recommendations"] = self._generate_recommendations(analysis["violations"])
        
        return analysis
    
    def _check_violation(self, text: str, subcat_data: dict) -> dict:
        """
        íŠ¹ì • í•˜ìœ„ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ìœ„ë°˜ ì—¬ë¶€ ê²€ì‚¬
        """
        result = {
            "is_violation": False,
            "matched_indicators": [],
            "matched_keywords": []
        }
        
        text_lower = text.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword in subcat_data.get("keywords", []):
            if keyword.lower() in text_lower:
                result["matched_keywords"].append(keyword)
        
        # ì¸ë””ì¼€ì´í„°(ë¬¸ë§¥ íŒ¨í„´) ë§¤ì¹­
        for indicator in subcat_data.get("indicators", []):
            # ì¸ë””ì¼€ì´í„°ì˜ í•µì‹¬ ë‹¨ì–´ë“¤ì´ í…ìŠ¤íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸
            indicator_words = [w for w in indicator.split() if len(w) > 2]
            match_count = sum(1 for w in indicator_words if w.lower() in text_lower)
            
            # í•µì‹¬ ë‹¨ì–´ì˜ 30% ì´ìƒ ë§¤ì¹­ë˜ë©´ í•´ë‹¹ ì¸ë””ì¼€ì´í„° ì ìš©
            if len(indicator_words) > 0 and match_count / len(indicator_words) >= 0.3:
                result["matched_indicators"].append(indicator)
        
        # í‚¤ì›Œë“œ 2ê°œ ì´ìƒ ë˜ëŠ” ì¸ë””ì¼€ì´í„° 1ê°œ ì´ìƒ ë§¤ì¹­ ì‹œ ìœ„ë°˜
        if len(result["matched_keywords"]) >= 1 or len(result["matched_indicators"]) >= 1:
            result["is_violation"] = True
        
        return result
    
    def _calculate_risk_score(self, detected_subcategories: list, violations: list) -> int:
        """
        ìœ„í—˜ ì ìˆ˜ ê³„ì‚° (ê³µì‹ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜)
        """
        if not violations:
            return 0
        
        # ê¸°ë³¸ ì ìˆ˜: ê°€ì¥ ë†’ì€ ìœ„ë°˜ì˜ ì ìˆ˜
        base_scores = [v["base_score"] for v in violations]
        max_score = max(base_scores) if base_scores else 0
        
        # ì¶”ê°€ ìœ„ë°˜ì— ëŒ€í•œ ê°€ì‚°ì  (ê°ê° 10ì ì”©, ìµœëŒ€ 30ì )
        additional_score = min(len(violations) - 1, 3) * 10
        
        # ìœ„ë°˜ ì¡°í•© ë³´ë„ˆìŠ¤
        combination_score = 0
        for (cat1, sub1), (cat2, sub2) in [(a, b) for i, a in enumerate(detected_subcategories) for b in detected_subcategories[i+1:]]:
            key1 = (sub1, sub2)
            key2 = (sub2, sub1)
            if key1 in self.combination_bonus:
                combination_score += self.combination_bonus[key1]
            elif key2 in self.combination_bonus:
                combination_score += self.combination_bonus[key2]
        
        total_score = max_score + additional_score + combination_score
        return min(total_score, 100)
    
    def _get_risk_level(self, score: int) -> str:
        """
        ì ìˆ˜ì— ë”°ë¥¸ ìœ„í—˜ ë“±ê¸‰
        """
        if score >= 80:
            return "ğŸ”´ ë§¤ìš° ë†’ìŒ (ì‚­ì œ ê°€ëŠ¥ì„± ë†’ìŒ)"
        elif score >= 60:
            return "ğŸŸ  ë†’ìŒ (ê²½ê³ /ì œí•œ ê°€ëŠ¥ì„±)"
        elif score >= 40:
            return "ğŸŸ¡ ì¤‘ê°„ (ì£¼ì˜ í•„ìš”)"
        elif score >= 20:
            return "ğŸŸ¢ ë‚®ìŒ"
        else:
            return "âœ… ì•ˆì „"
    
    def _generate_recommendations(self, violations: list) -> list:
        """
        ê³µì‹ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ê¶Œê³ ì‚¬í•­ ìƒì„±
        """
        recommendations = []
        
        for v in violations:
            cat = v["category"]
            sub = v["subcategory"]
            
            if sub == "ì§ì—…_ì‚¬ê¸°":
                recommendations.append(
                    "âš ï¸ [ì§ì—… ì‚¬ê¸° ì˜¤ì¸ ê°€ëŠ¥] 'ì—…ì¢…ë§Œ ê´œì°®ìœ¼ë©´', 'ì‰½ê²Œ', 'ë³´ì¥' ê°™ì€ í‘œí˜„ ì œê±° â†’ "
                    "'ìš”ê±´ ì¶©ì¡± ì‹œ ê²€í†  ê°€ëŠ¥', 'ì¼€ì´ìŠ¤ë³„ ìƒì´' ë“±ìœ¼ë¡œ ë³€ê²½"
                )
            elif sub == "ê°€ì§œ_ë¬¸ì„œ_ì‚¬ê¸°":
                recommendations.append(
                    "âš ï¸ [ê°€ì§œ ë¬¸ì„œ ì‚¬ê¸° ì˜¤ì¸ ê°€ëŠ¥] 'ì¸ì¦ ê°€ì', 'ëŒ€í–‰' í‘œí˜„ ì œê±° â†’ "
                    "'ì¸ì¦ ìš”ê±´ ì•ˆë‚´', 'ê³µì‹ ì ˆì°¨ í™•ì¸ í•„ìš”' ë“±ìœ¼ë¡œ ë³€ê²½"
                )
            elif sub == "ë°˜ë³µ_ê²Œì‹œ":
                recommendations.append(
                    "âš ï¸ [ìŠ¤íŒ¸ íƒì§€] ë™ì¼/ìœ ì‚¬ ë¬¸êµ¬ ë°˜ë³µ ê²Œì‹œ ê¸ˆì§€ â†’ "
                    "ê°™ì€ ì£¼ì œë¼ë„ ë¬¸ì¥ êµ¬ì¡°/í‘œí˜„ì„ ë‹¤ë¥´ê²Œ ì‘ì„±"
                )
            elif sub == "ì°¸ì—¬_ìœ ë„":
                recommendations.append(
                    "âš ï¸ [ì°¸ì—¬ ìœ ë„ ìŠ¤íŒ¸] 'DM ì£¼ì„¸ìš”', 'ì¢‹ì•„ìš” ëˆ„ë¥´ë©´' ë“± ê³¼ë„í•œ CTA ìµœì†Œí™”"
                )
            elif sub == "ê¸°ë§Œì _ì˜¤í•´_ìœ ë°œ":
                recommendations.append(
                    "âš ï¸ [ê³¼ì¥/ê¸°ë§Œ ì˜¤ì¸ ê°€ëŠ¥] '100%', 'ë¬´ì¡°ê±´', 'ë³´ì¥' í‘œí˜„ ì œê±° â†’ "
                    "'ê°€ëŠ¥ì„±', 'ê²€í†  í•„ìš”', 'ì¼€ì´ìŠ¤ë³„ ìƒì´' ë“±ìœ¼ë¡œ ì™„í™”"
                )
            elif sub == "íˆ¬ì_ê¸ˆì „_ì‚¬ê¸°":
                recommendations.append(
                    "âš ï¸ [íˆ¬ì ì‚¬ê¸° ì˜¤ì¸ ê°€ëŠ¥] ìˆ˜ìµ ë³´ì¥, ë¬´ìœ„í—˜ íˆ¬ì í‘œí˜„ ì ˆëŒ€ ê¸ˆì§€"
                )
        
        return recommendations
    
    def analyze_all_posts(self, posts: list) -> list:
        """
        ì „ì²´ ê²Œì‹œë¬¼ ë¶„ì„ + ì¤‘ë³µ ê²€ì‚¬
        """
        results = []
        
        for i, post in enumerate(posts):
            analysis = self.analyze_post(post)
            
            # ì¤‘ë³µ/ë°˜ë³µ ê²Œì‹œ ê²€ì‚¬
            duplicates = self._find_duplicates(post["text"], posts, i)
            
            if duplicates:
                # ì¤‘ë³µ ë°œê²¬ ì‹œ ìŠ¤íŒ¸ > ë°˜ë³µ_ê²Œì‹œ ìœ„ë°˜ ì¶”ê°€
                analysis["violations"].append({
                    "category": "ìŠ¤íŒ¸",
                    "subcategory": "ë°˜ë³µ_ê²Œì‹œ",
                    "matched_indicators": [f"{len(duplicates)}ê°œì˜ ìœ ì‚¬ ê²Œì‹œë¬¼ ë°œê²¬"],
                    "matched_keywords": [],
                    "base_score": 80
                })
                analysis["violation_details"].append(
                    f"[ìŠ¤íŒ¸/ë°˜ë³µ_ê²Œì‹œ] {len(duplicates)}ê°œì˜ ìœ ì‚¬ ê²Œì‹œë¬¼ ë°œê²¬ (ìœ ì‚¬ë„ 80% ì´ìƒ)"
                )
                analysis["official_policy_refs"].append(
                    "ì»¤ë®¤ë‹ˆí‹° ê·œì • > ìŠ¤íŒ¸ > 'ë§¤ìš° ë¹ˆë²ˆí•œ ë¹ˆë„ë¡œ ì½˜í…ì¸ ë¥¼ ê²Œì‹œ' / 'ë°˜ë³µì ì¸ ì½˜í…ì¸  ê²Œì‹œ'"
                )
                analysis["recommendations"].append(
                    "âš ï¸ [ìŠ¤íŒ¸ íƒì§€] ë™ì¼/ìœ ì‚¬ ë¬¸êµ¬ ë°˜ë³µ ê²Œì‹œ ê¸ˆì§€ â†’ ê°™ì€ ì£¼ì œë¼ë„ ë¬¸ì¥ êµ¬ì¡°/í‘œí˜„ì„ ë‹¤ë¥´ê²Œ ì‘ì„±"
                )
                
                # ì ìˆ˜ ì¬ê³„ì‚°
                analysis["risk_score"] = min(analysis["risk_score"] + 30, 100)
                analysis["risk_level"] = self._get_risk_level(analysis["risk_score"])
            
            analysis["is_duplicate"] = len(duplicates) > 0
            analysis["duplicate_count"] = len(duplicates)
            
            results.append(analysis)
        
        return results
    
    def _find_duplicates(self, text: str, all_posts: list, current_index: int, threshold: float = 0.8) -> list:
        """
        ìœ ì‚¬í•œ ê²Œì‹œë¬¼ ì°¾ê¸°
        """
        duplicates = []
        for i, post in enumerate(all_posts):
            if i != current_index:
                similarity = SequenceMatcher(None, text, post["text"]).ratio()
                if similarity >= threshold:
                    duplicates.append({
                        "index": i,
                        "similarity": round(similarity * 100, 1)
                    })
        return duplicates


def generate_summary(results: list) -> dict:
    """
    ì „ì²´ ë¶„ì„ ìš”ì•½ ìƒì„±
    """
    total = len(results)
    if total == 0:
        return {
            "total_posts": 0,
            "critical_count": 0,
            "high_risk_count": 0,
            "medium_risk_count": 0,
            "low_risk_count": 0,
            "safe_count": 0,
            "duplicate_count": 0,
            "average_risk_score": 0,
            "top_violations": []
        }
    
    # ë“±ê¸‰ë³„ ì¹´ìš´íŠ¸
    critical = sum(1 for r in results if "ë§¤ìš° ë†’ìŒ" in r["risk_level"])
    high = sum(1 for r in results if "ë†’ìŒ" in r["risk_level"] and "ë§¤ìš°" not in r["risk_level"])
    medium = sum(1 for r in results if "ì¤‘ê°„" in r["risk_level"])
    low = sum(1 for r in results if "ë‚®ìŒ" in r["risk_level"])
    safe = sum(1 for r in results if "ì•ˆì „" in r["risk_level"])
    duplicates = sum(1 for r in results if r.get("is_duplicate", False))
    
    # ê°€ì¥ ë¹ˆë²ˆí•œ ìœ„ë°˜ ìœ í˜•
    all_violations = []
    for r in results:
        for v in r.get("violations", []):
            all_violations.append(f"{v['category']}/{v['subcategory']}")
    
    from collections import Counter
    violation_counts = Counter(all_violations)
    top_violations = violation_counts.most_common(5)
    
    return {
        "total_posts": total,
        "critical_count": critical,
        "high_risk_count": high,
        "medium_risk_count": medium,
        "low_risk_count": low,
        "safe_count": safe,
        "duplicate_count": duplicates,
        "average_risk_score": round(sum(r["risk_score"] for r in results) / total, 1),
        "top_violations": top_violations
    }
