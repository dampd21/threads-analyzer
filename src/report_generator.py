# src/report_generator.py
import os
from datetime import datetime
from typing import List, Dict

class ReportGenerator:
    def __init__(self, username: str, start_date: str, end_date: str):
        self.username = username
        self.start_date = start_date
        self.end_date = end_date
    
    def generate_markdown_report(self, results: List[Dict], summary: Dict, output_dir: str) -> str:
        """
        ìƒì„¸ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report = f"""# ğŸ“Š Threads ê°€ì´ë“œë¼ì¸ ë¶„ì„ ë¦¬í¬íŠ¸

## ê¸°ë³¸ ì •ë³´
- **ë¶„ì„ ëŒ€ìƒ**: @{self.username}
- **ë¶„ì„ ê¸°ê°„**: {self.start_date} ~ {self.end_date}
- **ë¶„ì„ ì‹œê°**: {timestamp}
- **ì´ ê²Œì‹œë¬¼**: {summary['total_posts']}ê°œ

---

## ğŸ“ˆ ìš”ì•½

| ìœ„í—˜ ë“±ê¸‰ | ê²Œì‹œë¬¼ ìˆ˜ | ë¹„ìœ¨ |
|-----------|-----------|------|
| ğŸ”´ ë†’ìŒ | {summary['high_risk_count']}ê°œ | {self._calc_percent(summary['high_risk_count'], summary['total_posts'])}% |
| ğŸŸ¡ ì¤‘ê°„ | {summary['medium_risk_count']}ê°œ | {self._calc_percent(summary['medium_risk_count'], summary['total_posts'])}% |
| ğŸŸ¢ ë‚®ìŒ | {summary['low_risk_count']}ê°œ | {self._calc_percent(summary['low_risk_count'], summary['total_posts'])}% |
| âœ… ì•ˆì „ | {summary['safe_count']}ê°œ | {self._calc_percent(summary['safe_count'], summary['total_posts'])}% |

- **ë°˜ë³µ/ì¤‘ë³µ ê²Œì‹œë¬¼**: {summary['duplicate_count']}ê°œ
- **í‰ê·  ìœ„í—˜ ì ìˆ˜**: {summary['average_risk_score']}/100

---

## âš ï¸ ìœ„í—˜ ê²Œì‹œë¬¼ ìƒì„¸

"""
        # ìœ„í—˜ ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        high_risk_posts = sorted(
            [r for r in results if r['risk_score'] > 0],
            key=lambda x: x['risk_score'],
            reverse=True
        )
        
        if high_risk_posts:
            for i, post in enumerate(high_risk_posts[:10], 1):
                report += f"""### {i}. {post['risk_level']} (ì ìˆ˜: {post['risk_score']}/100)

**ë‚ ì§œ**: {post['datetime'][:10] if post['datetime'] else 'ì•Œ ìˆ˜ ì—†ìŒ'}

**ë‚´ìš©**:
> {post['text'][:200]}{'...' if len(post['text']) > 200 else ''}

**íƒì§€ëœ ë¬¸ì œ**:
"""
                if post['spam_detected']:
                    report += f"- ìŠ¤íŒ¸ì„± í‘œí˜„: `{', '.join(post['spam_detected'])}`\n"
                if post['exaggeration_detected']:
                    report += f"- ê³¼ì¥ í‘œí˜„: `{', '.join(post['exaggeration_detected'])}`\n"
                if post['broker_detected']:
                    report += f"- ëŒ€í–‰/ë¸Œë¡œì»¤ í‘œí˜„: `{', '.join(post['broker_detected'])}`\n"
                if post['cta_detected']:
                    report += f"- ê³¼ë„í•œ ìœ ë„: `{', '.join(post['cta_detected'])}`\n"
                if post.get('is_duplicate'):
                    report += f"- âš ï¸ ì¤‘ë³µ ê²Œì‹œë¬¼ ë°œê²¬\n"
                
                report += f"""
**ê¶Œê³ ì‚¬í•­**:
"""
                for rec in post['recommendations']:
                    report += f"- {rec}\n"
                
                report += f"\n**ë§í¬**: [{post['link']}]({post['link']})\n\n---\n\n"
        else:
            report += "> ìœ„í—˜ ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤! ğŸ‰\n\n"
        
        # ì¤‘ë³µ ê²Œì‹œë¬¼ ì„¹ì…˜
        duplicates = [r for r in results if r.get('is_duplicate')]
        if duplicates:
            report += """## ğŸ”„ ì¤‘ë³µ/ë°˜ë³µ ê²Œì‹œë¬¼

ë°˜ë³µì ì¸ ë™ì¼ ë¬¸êµ¬ ê²Œì‹œëŠ” ìŠ¤íŒ¸ìœ¼ë¡œ ë¶„ë¥˜ë  ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.

| ë‚ ì§œ | ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° | ìœ„í—˜ ë“±ê¸‰ |
|------|--------------|-----------|
"""
            for dup in duplicates:
                preview = dup['text'][:30] + '...' if len(dup['text']) > 30 else dup['text']
                preview = preview.replace('|', '\\|').replace('\n', ' ')
                date = dup['datetime'][:10] if dup['datetime'] else '-'
                report += f"| {date} | {preview} | {dup['risk_level']} |\n"
            
            report += "\n"
        
        # ê°œì„  ê¶Œì¥ì‚¬í•­
        report += """---

## ğŸ’¡ ì „ì²´ ê°œì„  ê¶Œì¥ì‚¬í•­

### í”¼í•´ì•¼ í•  íŒ¨í„´
1. **ë™ì¼/ìœ ì‚¬ ë¬¸êµ¬ ë°˜ë³µ ê²Œì‹œ** - ìŠ¤íŒ¸ íƒì§€ 1ìˆœìœ„
2. **ê³¼ì¥/ë³´ì¥ í‘œí˜„** - "ë¬´ì¡°ê±´", "100%", "ì‰½ê²Œ" ë“±
3. **ë¸Œë¡œì»¤/ëŒ€í–‰ ë‰˜ì•™ìŠ¤** - "ìŠ¤íŒ©ì—…", "ì¸ì¦ ê°€ì", "ëŒ€í–‰" ë“±
4. **ê³¼ë„í•œ CTA** - "DM ì£¼ì„¸ìš”", "ë§í¬ í´ë¦­" ë°˜ë³µ

### ê¶Œì¥í•˜ëŠ” íŒ¨í„´
1. **ì •ë³´í˜• í†¤** - "ìš”ê±´ ì¶©ì¡± ì‹œ ê²€í†  ê°€ëŠ¥", "ì¼€ì´ìŠ¤ë³„ ìƒì´"
2. **ê³µì‹ ê¸°ì¤€ ì–¸ê¸‰** - "ê³µì‹ ê¸°ê´€ í™•ì¸ í•„ìš”"
3. **ê²½í—˜ ê³µìœ  í†¤** - "ì œ ê²½í—˜ìœ¼ë¡œëŠ”...", "ì°¸ê³ ë¡œ..."
4. **ë‹¤ì–‘í•œ ì½˜í…ì¸ ** - ë™ì¼ ì£¼ì œë„ ë‹¤ë¥¸ í‘œí˜„/êµ¬ì„±ìœ¼ë¡œ

---

## ğŸ“ ì°¸ê³  ìë£Œ
- [Threads ì»¤ë®¤ë‹ˆí‹° ê°€ì´ë“œë¼ì¸](https://help.instagram.com/769983657850450)
- [Meta ì»¤ë®¤ë‹ˆí‹° ìŠ¤íƒ ë‹¤ë“œ](https://transparency.meta.com/policies/community-standards/)

---

*ì´ ë¦¬í¬íŠ¸ëŠ” ìë™ ë¶„ì„ ë„êµ¬ì— ì˜í•´ ìƒì„±ë˜ì—ˆìœ¼ë©°, ì‹¤ì œ Metaì˜ íŒë‹¨ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.*
"""
        
        # íŒŒì¼ ì €ì¥
        report_path = os.path.join(output_dir, f"report_{self.username}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        return report_path
    
    def _calc_percent(self, count: int, total: int) -> float:
        if total == 0:
            return 0
        return round(count / total * 100, 1)


class AlternativeTextGenerator:
    """
    ìœ„í—˜ ê²Œì‹œë¬¼ì— ëŒ€í•œ ëŒ€ì²´ ë¬¸êµ¬ ìƒì„±
    """
    
    REPLACEMENTS = {
        # ìŠ¤íŒ¸ì„± â†’ ì •ë³´í˜•
        "ê¸°ì–µí•´": "ì°¸ê³ í•´ ë³´ì„¸ìš”",
        "ê°€ì": "ê²€í† í•´ ë³¼ ìˆ˜ ìˆì–´ìš”",
        "ë¬´ì¡°ê±´": "ì¼ì • ìš”ê±´ ì¶©ì¡± ì‹œ",
        "ë³´ì¥": "ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”",
        "100%": "ëŒ€ë¶€ë¶„ì˜ ê²½ìš°",
        "ë°”ë¡œ ê°€ëŠ¥": "ì ˆì°¨ë¥¼ ê±°ì¹˜ë©´ ê°€ëŠ¥",
        "ì‰½ê²Œ": "ì¤€ë¹„í•˜ë©´",
        "DM ì£¼ì„¸ìš”": "ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´",
        "ëŒ“ê¸€ ë‹¬ë©´": "ê¶ê¸ˆí•˜ì‹  ì ì€",
        
        # ê³¼ì¥ â†’ ì™„í™”
        "ì—…ì¢…ë§Œ ê´œì°®ìœ¼ë©´": "ì—…ì¢… ìš”ê±´ì„ ì¶©ì¡±í•˜ë©´",
        "ì¡°ê±´ë§Œ ë§ìœ¼ë©´": "ìš”ê±´ì„ ì¶©ì¡±í•˜ëŠ” ê²½ìš°",
        "ëˆ„êµ¬ë‚˜ ê°€ëŠ¥": "ìš”ê±´ì— í•´ë‹¹í•˜ë©´ ê²€í†  ê°€ëŠ¥",
        "ëŒ€ë°•": "ì¢‹ì€ ê²°ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆì–´ìš”",
        "í™•ì‹¤": "ê°€ëŠ¥ì„±ì´ ë†’ì•„ìš”",
        
        # ë¸Œë¡œì»¤ â†’ ì •ë³´ ê³µìœ 
        "ëŒ€í–‰": "ê´€ë ¨ ì •ë³´ ì•ˆë‚´",
        "ìŠ¤íŒ©ì—…": "ë²•ì¸ ì¤€ë¹„ ì‚¬í•­",
        "ì¸ì¦ ê°€ì": "ì¸ì¦ ìš”ê±´ ì •ë¦¬",
        "ë¹ ë¥´ê²Œ ì²˜ë¦¬": "íš¨ìœ¨ì ìœ¼ë¡œ ì¤€ë¹„",
    }
    
    def generate_alternative(self, original_text: str, detected_keywords: List[str]) -> str:
        """
        ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ìœ„í—˜ í‚¤ì›Œë“œë¥¼ ëŒ€ì²´í•œ ë²„ì „ ìƒì„±
        """
        alternative = original_text
        
        for keyword in detected_keywords:
            if keyword in self.REPLACEMENTS:
                alternative = alternative.replace(keyword, self.REPLACEMENTS[keyword])
        
        return alternative
    
    def generate_safe_versions(self, original_text: str, detected_issues: Dict) -> List[Dict]:
        """
        ì—¬ëŸ¬ ë²„ì „ì˜ ì•ˆì „í•œ ëŒ€ì²´ ë¬¸êµ¬ ìƒì„±
        """
        all_detected = (
            detected_issues.get('spam_detected', []) +
            detected_issues.get('exaggeration_detected', []) +
            detected_issues.get('broker_detected', []) +
            detected_issues.get('cta_detected', [])
        )
        
        if not all_detected:
            return []
        
        versions = []
        
        # ë²„ì „ 1: í‚¤ì›Œë“œ ì§ì ‘ ëŒ€ì²´
        v1 = self.generate_alternative(original_text, all_detected)
        versions.append({
            "type": "í‚¤ì›Œë“œ ëŒ€ì²´",
            "text": v1
        })
        
        # ë²„ì „ 2: ì •ë³´í˜• í†¤
        v2 = self._convert_to_informative(original_text)
        versions.append({
            "type": "ì •ë³´í˜•",
            "text": v2
        })
        
        # ë²„ì „ 3: ê²½í—˜ ê³µìœ í˜•
        v3 = self._convert_to_experience(original_text)
        versions.append({
            "type": "ê²½í—˜ ê³µìœ í˜•",
            "text": v3
        })
        
        return versions
    
    def _convert_to_informative(self, text: str) -> str:
        """
        ì •ë³´í˜• í†¤ìœ¼ë¡œ ë³€í™˜
        """
        # ê°„ë‹¨í•œ ë³€í™˜ ë¡œì§
        prefix = "[ì •ë³´ ê³µìœ ] "
        suffix = "\n\nâ€» ê°œë³„ ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ ê³µì‹ ê¸°ì¤€ì„ í™•ì¸í•´ ì£¼ì„¸ìš”."
        
        # ìœ„í—˜ í‚¤ì›Œë“œ ì œê±°
        clean = text
        for keyword in self.REPLACEMENTS.keys():
            clean = clean.replace(keyword, self.REPLACEMENTS.get(keyword, ""))
        
        return prefix + clean.strip() + suffix
    
    def _convert_to_experience(self, text: str) -> str:
        """
        ê²½í—˜ ê³µìœ í˜•ìœ¼ë¡œ ë³€í™˜
        """
        prefix = "ì œ ê²½í—˜ì„ ê³µìœ í•˜ìë©´, "
        suffix = "\n\në¬¼ë¡  ì¼€ì´ìŠ¤ë§ˆë‹¤ ë‹¤ë¥´ë‹ˆ ì°¸ê³ ë§Œ í•´ì£¼ì„¸ìš”."
        
        clean = text
        for keyword in self.REPLACEMENTS.keys():
            clean = clean.replace(keyword, self.REPLACEMENTS.get(keyword, ""))
        
        return prefix + clean.strip() + suffix
