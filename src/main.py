# src/main.py
import asyncio
import pandas as pd
from datetime import datetime
import os
import sys

# ìƒìœ„ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import THREADS_USERNAME, START_DATE, END_DATE, MAX_POSTS, OUTPUT_DIR
from scraper import ThreadsScraper
from analyzer import GuidelineAnalyzer, generate_summary


async def main():
    print("=" * 60)
    print("Threads ê²Œì‹œë¬¼ ê°€ì´ë“œë¼ì¸ ë¶„ì„ê¸°")
    print("=" * 60)
    print(f"ì‚¬ìš©ì: @{THREADS_USERNAME}")
    print(f"ê¸°ê°„: {START_DATE} ~ {END_DATE}")
    print(f"ìµœëŒ€ ìˆ˜ì§‘: {MAX_POSTS}ê°œ")
    print("=" * 60)
    
    # 1. í¬ë¡¤ë§
    scraper = ThreadsScraper(
        username=THREADS_USERNAME,
        start_date=START_DATE,
        end_date=END_DATE
    )
    posts = await scraper.scrape_posts(max_posts=MAX_POSTS)
    
    if not posts:
        print("[!] ìˆ˜ì§‘ëœ ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        # ë¹ˆ ê²°ê³¼ íŒŒì¼ ìƒì„±
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        with open(os.path.join(OUTPUT_DIR, "summary.txt"), "w", encoding="utf-8") as f:
            f.write("ìˆ˜ì§‘ëœ ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.\n")
        return
    
    # 2. ë¶„ì„
    print(f"\n[*] {len(posts)}ê°œ ê²Œì‹œë¬¼ ë¶„ì„ ì¤‘...")
    analyzer = GuidelineAnalyzer()
    results = analyzer.analyze_all_posts(posts)
    
    # 3. ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    summary = generate_summary(results)
    print(f"ì´ ê²Œì‹œë¬¼: {summary['total_posts']}ê°œ")
    print(f"ğŸ”´ ë†’ì€ ìœ„í—˜: {summary['high_risk_count']}ê°œ")
    print(f"ğŸŸ¡ ì¤‘ê°„ ìœ„í—˜: {summary['medium_risk_count']}ê°œ")
    print(f"ğŸŸ¢ ë‚®ì€ ìœ„í—˜: {summary['low_risk_count']}ê°œ")
    print(f"âœ… ì•ˆì „: {summary['safe_count']}ê°œ")
    print(f"ë°˜ë³µ/ì¤‘ë³µ: {summary['duplicate_count']}ê°œ")
    print(f"í‰ê·  ìœ„í—˜ ì ìˆ˜: {summary['average_risk_score']}/100")
    
    # 4. CSV ì €ì¥
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    df_data = []
    for r in results:
        df_data.append({
            "ì‚¬ìš©ìëª…": r["username"],
            "ë‚ ì§œì‹œê°„": r["datetime"],
            "ê²Œì‹œë¬¼ë‚´ìš©": r["text"],
            "ë§í¬": r["link"],
            "ì¢‹ì•„ìš”": r["likes"],
            "ë‹µê¸€": r["replies"],
            "ë¦¬í¬ìŠ¤íŠ¸": r["reposts"],
            "ìœ„í—˜ì ìˆ˜": r["risk_score"],
            "ìœ„í—˜ë“±ê¸‰": r["risk_level"],
            "ìŠ¤íŒ¸í‚¤ì›Œë“œ": ", ".join(r["spam_detected"]),
            "ê³¼ì¥í‘œí˜„": ", ".join(r["exaggeration_detected"]),
            "ë¸Œë¡œì»¤í‘œí˜„": ", ".join(r["broker_detected"]),
            "ìœ ë„í‘œí˜„": ", ".join(r["cta_detected"]),
            "ì¤‘ë³µì—¬ë¶€": "ì˜ˆ" if r.get("is_duplicate", False) else "ì•„ë‹ˆì˜¤",
            "ê¶Œê³ ì‚¬í•­": " | ".join(r["recommendations"])
        })
    
    df = pd.DataFrame(df_data)
    
    # íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"threads_{THREADS_USERNAME}_{START_DATE}_{END_DATE}_{timestamp}"
    
    # UTF-8 CSV (ë²”ìš©)
    csv_path = os.path.join(OUTPUT_DIR, f"{filename}.csv")
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    print(f"\nâœ… CSV ì €ì¥: {csv_path}")
    
    # ìš”ì•½ íŒŒì¼ ì €ì¥ (GitHub Actions Summaryìš©)
    summary_path = os.path.join(OUTPUT_DIR, "summary.txt")
    with open(summary_path, "w", encoding="utf-8") as f:
        f.write(f"### ë¶„ì„ ê²°ê³¼\n")
        f.write(f"- ì´ ê²Œì‹œë¬¼: **{summary['total_posts']}ê°œ**\n")
        f.write(f"- ğŸ”´ ë†’ì€ ìœ„í—˜: **{summary['high_risk_count']}ê°œ**\n")
        f.write(f"- ğŸŸ¡ ì¤‘ê°„ ìœ„í—˜: **{summary['medium_risk_count']}ê°œ**\n")
        f.write(f"- ğŸŸ¢ ë‚®ì€ ìœ„í—˜: **{summary['low_risk_count']}ê°œ**\n")
        f.write(f"- âœ… ì•ˆì „: **{summary['safe_count']}ê°œ**\n")
        f.write(f"- ë°˜ë³µ/ì¤‘ë³µ: **{summary['duplicate_count']}ê°œ**\n")
        f.write(f"- í‰ê·  ìœ„í—˜ ì ìˆ˜: **{summary['average_risk_score']}/100**\n")
        
        # ìœ„í—˜í•œ ê²Œì‹œë¬¼ ìƒìœ„ 5ê°œ
        high_risk_posts = sorted(results, key=lambda x: x["risk_score"], reverse=True)[:5]
        if high_risk_posts and high_risk_posts[0]["risk_score"] > 0:
            f.write(f"\n### âš ï¸ ì£¼ì˜ í•„ìš” ê²Œì‹œë¬¼ (ìƒìœ„ 5ê°œ)\n")
            for i, post in enumerate(high_risk_posts, 1):
                if post["risk_score"] > 0:
                    text_preview = post["text"][:50] + "..." if len(post["text"]) > 50 else post["text"]
                    f.write(f"{i}. **{post['risk_level']}** (ì ìˆ˜: {post['risk_score']}) - {text_preview}\n")
    
    print(f"âœ… ìš”ì•½ ì €ì¥: {summary_path}")
    print("\në¶„ì„ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(main())
