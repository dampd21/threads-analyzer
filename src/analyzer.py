# src/analyzer.py
from difflib import SequenceMatcher
from config import RISK_PATTERNS, DUPLICATE_THRESHOLD

class GuidelineAnalyzer:
    def __init__(self):
        self.risk_patterns = RISK_PATTERNS
    
    def analyze_post(self, post: dict) -> dict:
        """
        ë‹¨ì¼ ê²Œì‹œë¬¼ ë¶„ì„
        """
        text = post.get("text", "")
        
        analysis = {
            "username": post.get("username", ""),
            "text": text,
            "datetime": post.get("datetime", ""),
            "link": post.get("link", ""),
            "likes": post.get("likes", 0),
            "replies": post.get("replies", 0),
            "reposts": post.get("reposts", 0),
            
            # ìœ„ë°˜ ë¶„ì„ ê²°ê³¼
            "spam_detected": [],
            "exaggeration_detected": [],
            "broker_detected": [],
            "cta_detected": [],
            
            # ì¢…í•© ì ìˆ˜
            "risk_score": 0,
            "risk_level": "ì•ˆì „",
            "recommendations": []
        }
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ê²€ì‚¬
        analysis["spam_detected"] = self._find_keywords(text, self.risk_patterns["spam_keywords"])
        analysis["exaggeration_detected"] = self._find_keywords(text, self.risk_patterns["exaggeration_keywords"])
        analysis["broker_detected"] = self._find_keywords(text, self.risk_patterns["broker_keywords"])
        analysis["cta_detected"] = self._find_keywords(text, self.risk_patterns["cta_patterns"])
        
        # ìœ„í—˜ ì ìˆ˜ ê³„ì‚°
        analysis["risk_score"] = self._calculate_risk_score(analysis)
        analysis["risk_level"] = self._get_risk_level(analysis["risk_score"])
        
        # ê¶Œê³ ì‚¬í•­ ìƒì„±
        analysis["recommendations"] = self._generate_recommendations(analysis)
        
        return analysis
    
    def analyze_all_posts(self, posts: list) -> list:
        """
        ì „ì²´ ê²Œì‹œë¬¼ ë¶„ì„ + ì¤‘ë³µ ê²€ì‚¬
        """
        results = []
        
        for i, post in enumerate(posts):
            analysis = self.analyze_post(post)
            
            # ì¤‘ë³µ/ë°˜ë³µ ê²Œì‹œ ê²€ì‚¬
            duplicates = self._find_duplicates(post["text"], posts, i)
            analysis["duplicate_count"] = len(duplicates)
            analysis["is_duplicate"] = len(duplicates) > 0
            
            if analysis["is_duplicate"]:
                analysis["risk_score"] += 30
                analysis["risk_score"] = min(analysis["risk_score"], 100)
                analysis["risk_level"] = self._get_risk_level(analysis["risk_score"])
                analysis["recommendations"].append("âš ï¸ ìœ ì‚¬í•œ ê²Œì‹œë¬¼ì´ ë°˜ë³µë¨ - ìŠ¤íŒ¸ìœ¼ë¡œ ì˜¤ì¸ë  ê°€ëŠ¥ì„± ë†’ìŒ")
            
            results.append(analysis)
        
        return results
    
    def _find_keywords(self, text: str, keywords: list) -> list:
        found = []
        text_lower = text.lower()
        for keyword in keywords:
            if keyword.lower() in text_lower:
                found.append(keyword)
        return found
    
    def _calculate_risk_score(self, analysis: dict) -> int:
        score = 0
        score += len(analysis["spam_detected"]) * 15
        score += len(analysis["exaggeration_detected"]) * 20
        score += len(analysis["broker_detected"]) * 25
        score += len(analysis["cta_detected"]) * 10
        return min(score, 100)
    
    def _get_risk_level(self, score: int) -> str:
        if score >= 70:
            return "ğŸ”´ ë†’ìŒ"
        elif score >= 40:
            return "ğŸŸ¡ ì¤‘ê°„"
        elif score >= 20:
            return "ğŸŸ¢ ë‚®ìŒ"
        else:
            return "âœ… ì•ˆì „"
    
    def _find_duplicates(self, text: str, all_posts: list, current_index: int) -> list:
        duplicates = []
        for i, post in enumerate(all_posts):
            if i != current_index:
                similarity = SequenceMatcher(None, text, post["text"]).ratio()
                if similarity >= DUPLICATE_THRESHOLD:
                    duplicates.append({
                        "index": i,
                        "similarity": round(similarity * 100, 1)
                    })
        return duplicates
    
    def _generate_recommendations(self, analysis: dict) -> list:
        recommendations = []
        
        if analysis["spam_detected"]:
            recommendations.append(f"ìŠ¤íŒ¸ì„± í‘œí˜„: {', '.join(analysis['spam_detected'])} â†’ ì •ë³´í˜• ë¬¸êµ¬ë¡œ ë³€ê²½")
        
        if analysis["exaggeration_detected"]:
            recommendations.append(f"ê³¼ì¥ í‘œí˜„: {', '.join(analysis['exaggeration_detected'])} â†’ ì™„í™” í‘œí˜„ ê¶Œì¥")
        
        if analysis["broker_detected"]:
            recommendations.append(f"ëŒ€í–‰/ë¸Œë¡œì»¤ ì˜¤ì¸: {', '.join(analysis['broker_detected'])} â†’ ì •ë³´ ê³µìœ  í†¤ìœ¼ë¡œ ë³€ê²½")
        
        if analysis["cta_detected"]:
            recommendations.append(f"ê³¼ë„í•œ ìœ ë„: {', '.join(analysis['cta_detected'])} â†’ ìµœì†Œí™” ê¶Œì¥")
        
        return recommendations


def generate_summary(results: list) -> dict:
    """
    ì „ì²´ ë¶„ì„ ìš”ì•½ ìƒì„±
    """
    total = len(results)
    if total == 0:
        return {
            "total_posts": 0,
            "high_risk_count": 0,
            "medium_risk_count": 0,
            "low_risk_count": 0,
            "safe_count": 0,
            "duplicate_count": 0,
            "average_risk_score": 0
        }
    
    high_risk = sum(1 for r in results if "ë†’ìŒ" in r["risk_level"])
    medium_risk = sum(1 for r in results if "ì¤‘ê°„" in r["risk_level"])
    low_risk = sum(1 for r in results if "ë‚®ìŒ" in r["risk_level"])
    safe = sum(1 for r in results if "ì•ˆì „" in r["risk_level"])
    duplicates = sum(1 for r in results if r.get("is_duplicate", False))
    
    return {
        "total_posts": total,
        "high_risk_count": high_risk,
        "medium_risk_count": medium_risk,
        "low_risk_count": low_risk,
        "safe_count": safe,
        "duplicate_count": duplicates,
        "average_risk_score": round(sum(r["risk_score"] for r in results) / total, 1)
    }
